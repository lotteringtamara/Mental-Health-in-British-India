{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning text files with a focus on Mental Health in British India\n",
    "In order to focus on the main keyword (or set of keywords), this notebook goes through the following steps:\n",
    "- Open files and create a pandas dataframe.\n",
    "- Filter rows based on specific set of keywords.\n",
    "- Run a spell check and correct words. This will only be useful if it doesn't change specific words like location names.\n",
    "- Lowercase words.\n",
    "- Export dataframe to csv for future data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # File manipulation\n",
    "import pandas as pd # For dataframe operations\n",
    "import numpy as np\n",
    "from collections import Counter # to count word occurance\n",
    "import re # Regix to remove punctuation from strings I split\n",
    "#from autocorrect import Speller # spell checker for an alternative df\n",
    "\n",
    "\n",
    "# Import Libraries\n",
    "\n",
    "# We need NLTK and Gensim for LDA Topic Modelling\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "import gensim\n",
    "from gensim import matutils, models\n",
    "from gensim import corpora\n",
    "\n",
    "import scipy.sparse\n",
    "import os # to access files for cleaning\n",
    "from collections import Counter # to count word occurance\n",
    "import re # Regix to remove punctuation from strings I split\n",
    "from shutil import copyfile # For copying clean files\n",
    "from sklearn.feature_extraction.text import CountVectorizer # For creating document-term matrix & excluding stop words\n",
    "from sklearn.feature_extraction import text # For getting stop words\n",
    "from wordcloud import WordCloud # For creating word clouds\n",
    "from textblob import TextBlob # For sentiment analysis\n",
    "import numpy as np # For dataframe analysis\n",
    "import pandas as pd # For dataframe analysis\n",
    "import matplotlib.pyplot as plt # For graphs\n",
    "import seaborn as sns # For graphs\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this list to add keywords 🧚\n",
    "keywords = ['lunatic', 'asylum', 'mental', 'hospital'] #think we should include 'mental' 'hospitals' here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tamaralottering/Desktop/british-india-papers'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IP/QB.10 m.91.b. No. 44. (NEW SERIES.) SCIENTI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IP/6/HG.s4. REPORT ON THE CALCUTTA MEDICAL INS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHOLERA IN INDIA, 1862 TO 1881. BENGAL PROVINC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vol. I 1931 THE Indian Journal of Veterinary S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IP/QB, 10 m.91.b No. 19. (NEW SERIES.) SCIENTI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>[NLS note: a graphic appears here - see image ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>REPORT ON THE WORKING OF THE MENTAL HOSPITALS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>ICAR. 15. VIII. 650 Vol. VIII 1938 THE Indian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>SLEEPING SICKNESS A SUMMARY OF THE WORK DONE B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>[NLS note: a graphic appears here - see image ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    IP/QB.10 m.91.b. No. 44. (NEW SERIES.) SCIENTI...\n",
       "1    IP/6/HG.s4. REPORT ON THE CALCUTTA MEDICAL INS...\n",
       "2    CHOLERA IN INDIA, 1862 TO 1881. BENGAL PROVINC...\n",
       "3    Vol. I 1931 THE Indian Journal of Veterinary S...\n",
       "4    IP/QB, 10 m.91.b No. 19. (NEW SERIES.) SCIENTI...\n",
       "..                                                 ...\n",
       "465  [NLS note: a graphic appears here - see image ...\n",
       "466  REPORT ON THE WORKING OF THE MENTAL HOSPITALS ...\n",
       "467  ICAR. 15. VIII. 650 Vol. VIII 1938 THE Indian ...\n",
       "468  SLEEPING SICKNESS A SUMMARY OF THE WORK DONE B...\n",
       "469  [NLS note: a graphic appears here - see image ...\n",
       "\n",
       "[470 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# walk through the /data folder and read text files to make a df\n",
    "textList = []\n",
    "for dirname, _, filenames in os.walk('/Users/tamaralottering/Desktop/nls-text-indiaPapers'):\n",
    "    for filename in filenames:\n",
    "        # print(os.path.join(dirname, filename))\n",
    "        myfile = os.path.join(dirname, filename)\n",
    "        with open(myfile, 'rb') as fopen:\n",
    "            q = fopen.read().decode('ISO-8859-1')\n",
    "            textList.append(q)\n",
    "uncleanDf = pd.DataFrame(textList)\n",
    "uncleanDf.columns = ['text']\n",
    "uncleanDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial cleaning\n",
    "def initialCleaning(mystring):\n",
    "    mystring = mystring.lower() # Text normalization: make string lowercase\n",
    "    mystring = re.sub(r'[^\\w\\s]','', mystring) # Text normalization: remove punctuation\n",
    "    mystring = re.sub('\\[.*?\\]', '', mystring) #Text normalization: remove text in square brackets\n",
    "    mystring = re.sub('https?://\\S+|www\\.\\S+', '', mystring) #Text normalization: remove links\n",
    "    mystring = re.sub('\\n', '', mystring) #Text normalization: remove linebreaks\n",
    "    mystring = re.sub('\\w*\\d\\w*', '', mystring)#Text normalization: \n",
    "    return mystring\n",
    "\n",
    "def countWords(string, wordsToCount):\n",
    "    splitString = string.split() # Split string into array of words\n",
    "    counts = Counter(splitString) # Get counts for each word like Counter({'dogs': 3, 'cute': 1})\n",
    "    count = 0 # Start the counter\n",
    "    for word in wordsToCount: # Loop through list of words and add the count\n",
    "        count = count + counts[word]\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanText = lambda text: initialCleaning(text) # Lambda function applies to all cells in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and Lemmatize the text (NLP standardisation methods)\n",
    "import nltk\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanDf = pd.DataFrame(uncleanDf.text.apply(cleanText)) # .apply() the function to all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no  new series scientific memoirs by officer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>report on the calcutta medical institutions f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cholera in india  to  bengal province  to  and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vol i  the indian journal of veterinary scienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ipqb   no  new series scientific memoirs by of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>nls note a graphic appears here  see image of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>report on the working of the mental hospitals ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>icar  viii  vol viii  the indian journal of ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>sleeping sickness a summary of the work done b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>nls note a graphic appears here  see image of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0      no  new series scientific memoirs by officer...\n",
       "1     report on the calcutta medical institutions f...\n",
       "2    cholera in india  to  bengal province  to  and...\n",
       "3    vol i  the indian journal of veterinary scienc...\n",
       "4    ipqb   no  new series scientific memoirs by of...\n",
       "..                                                 ...\n",
       "465  nls note a graphic appears here  see image of ...\n",
       "466  report on the working of the mental hospitals ...\n",
       "467  icar  viii  vol viii  the indian journal of ve...\n",
       "468  sleeping sickness a summary of the work done b...\n",
       "469  nls note a graphic appears here  see image of ...\n",
       "\n",
       "[470 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanerDfList = []\n",
    "for index, row in cleanDf.iterrows():\n",
    "    count = countWords(cleanDf['text'].iloc[index], keywords)\n",
    "    if(count>4):\n",
    "        cleanerDfList.append(cleanDf['text'].iloc[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>report on the calcutta medical institutions f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cholera in india  to  bengal province  to  and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vol i  the indian journal of veterinary scienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ipqb   no  new series scientific memoirs by of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gtx \\rsi the  phi price\\rstatistical returns o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>\\rnls note a graphic appears here  see image o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>nls note a graphic appears here  see image of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>nls note a graphic appears here  see image of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>report on the working of the mental hospitals ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>icar  viii  vol viii  the indian journal of ve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0     report on the calcutta medical institutions f...\n",
       "1    cholera in india  to  bengal province  to  and...\n",
       "2    vol i  the indian journal of veterinary scienc...\n",
       "3    ipqb   no  new series scientific memoirs by of...\n",
       "4    gtx \\rsi the  phi price\\rstatistical returns o...\n",
       "..                                                 ...\n",
       "279  \\rnls note a graphic appears here  see image o...\n",
       "280  nls note a graphic appears here  see image of ...\n",
       "281  nls note a graphic appears here  see image of ...\n",
       "282  report on the working of the mental hospitals ...\n",
       "283  icar  viii  vol viii  the indian journal of ve...\n",
       "\n",
       "[284 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanerDf = pd.DataFrame(cleanerDfList)\n",
    "cleanerDf.columns = ['text']\n",
    "cleanerDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaned Export\n",
    "- cleanerDf refers to the clean dataframe that includes all documents that contain the main keywords with all text in lowercase and punctuation removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is a process to automatically identify topics present, and to derive hidden patterns exhibited by a text corpus. \n",
    "\n",
    "- Topic Modelling is an unsupervised machine learning approach used for finding and observing the bunch of words (called “topics”) in large clusters of texts. \n",
    "\n",
    "- Topics can be defined as “a repeating pattern of co-occurring terms in a corpus”. A good topic model should result in – “health”, “doctor”, “patient”, “hospital” for a topic – Healthcare, and “farm”, “crops”, “wheat” for a topic – “Farming”.\n",
    "\n",
    "- Topic Models are very useful for the purpose for document clustering, organizing large blocks of textual data, information retrieval from unstructured text and feature selection. \n",
    "\n",
    "Resources:\n",
    "https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tamaralottering/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/tamaralottering/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize corpus and Filter nouns and adjectives from the corpus (POS tagging)\n",
    "def partsOfSpeechFilter(text):\n",
    "    isNounAdj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nounsAdj = [word for (word, pos) in pos_tag(tokenized) if isNounAdj(pos)] \n",
    "    return ' '.join(nounsAdj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Preparing Document-Term Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run any mathematical model on text corpus, it is a good practice to convert it into a matrix representation. LDA model looks for repeating term patterns in the entire DT matrix.\n",
    "\n",
    "- “gensim” is a clean and beautiful library to handle text data. It is scalable, robust and efficient.\n",
    "- convert a corpus into a document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply parts of speech filter to filter out nouns and adjectives \n",
    "dfMH = pd.DataFrame(cleanerDf.text.apply(partsOfSpeechFilter)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__</th>\n",
       "      <th>___</th>\n",
       "      <th>____</th>\n",
       "      <th>_____</th>\n",
       "      <th>______</th>\n",
       "      <th>_______</th>\n",
       "      <th>________</th>\n",
       "      <th>_________</th>\n",
       "      <th>__________</th>\n",
       "      <th>___________</th>\n",
       "      <th>...</th>\n",
       "      <th>être</th>\n",
       "      <th>ídar</th>\n",
       "      <th>îstrus</th>\n",
       "      <th>óf</th>\n",
       "      <th>ôkpho</th>\n",
       "      <th>öocysts</th>\n",
       "      <th>öotype</th>\n",
       "      <th>ùpon</th>\n",
       "      <th>únmádmadness</th>\n",
       "      <th>über</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284 rows × 142100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     __  ___  ____  _____  ______  _______  ________  _________  __________  \\\n",
       "0     0    0     0      0       0        0         0          0           0   \n",
       "1     0    0     0      0       0        0         0          0           0   \n",
       "2     0    0     0      0       0        0         0          0           0   \n",
       "3     0    0     0      0       0        0         0          0           0   \n",
       "4    12    5     5      5       1        0         0          0           0   \n",
       "..   ..  ...   ...    ...     ...      ...       ...        ...         ...   \n",
       "279   0    0     0      0       0        0         0          0           0   \n",
       "280   0    0     0      0       0        0         0          0           0   \n",
       "281   0    0     0      0       0        0         0          0           0   \n",
       "282   0    0     0      0       0        0         0          0           0   \n",
       "283   0    0     0      0       0        0         0          0           0   \n",
       "\n",
       "     ___________  ...  être  ídar  îstrus  óf  ôkpho  öocysts  öotype  ùpon  \\\n",
       "0              0  ...     0     0       0   0      0        0       0     0   \n",
       "1              0  ...     0     0       0   0      0        0       0     0   \n",
       "2              0  ...     0     0       0   0      0        0       0     0   \n",
       "3              0  ...     0     0       0   0      0        0       0     0   \n",
       "4              0  ...     0     0       0   0      0        0       0     0   \n",
       "..           ...  ...   ...   ...     ...  ..    ...      ...     ...   ...   \n",
       "279            0  ...     0     0       0   0      0        0       0     0   \n",
       "280            0  ...     0     1       0   0      0        0       0     0   \n",
       "281            0  ...     0     0       0   0      0        0       0     0   \n",
       "282            0  ...     0     0       0   0      0        0       0     0   \n",
       "283            0  ...     0     0       0   0      0        0       0     0   \n",
       "\n",
       "     únmádmadness  über  \n",
       "0               0     0  \n",
       "1               0     0  \n",
       "2               0     0  \n",
       "3               0     0  \n",
       "4               0     0  \n",
       "..            ...   ...  \n",
       "279             0     0  \n",
       "280             0     0  \n",
       "281             0     0  \n",
       "282             0     0  \n",
       "283             0     0  \n",
       "\n",
       "[284 rows x 142100 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer is used to convert a collection of text documents to a vector of term/token counts.\n",
    "# Get the document term matrix\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "dataVectorizer = vectorizer.fit_transform(dfMH.text) #initial fitting of parameters on the training set x\n",
    "dataDtmNA = pd.DataFrame(dataVectorizer.toarray(), columns = vectorizer.get_feature_names())\n",
    "dataDtmNA # This is the document term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map ID to words\n",
    "corpusNA = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(dataDtmNA.transpose()))\n",
    "id2wordNA = dict((v, k) for k, v in vectorizer.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Running LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.013*\"plague\" + 0.011*\"cases\" + 0.009*\"hospital\" + 0.009*\"medical\" + 0.006*\"disease\" + 0.006*\"case\" + 0.006*\"deaths\" + 0.006*\"number\" + 0.006*\"officer\" + 0.005*\"district\"'),\n",
       " (1,\n",
       "  '0.039*\"total\" + 0.025*\"year\" + 0.016*\"number\" + 0.014*\"males\" + 0.013*\"females\" + 0.010*\"vaccination\" + 0.010*\"statement\" + 0.008*\"average\" + 0.008*\"asylum\" + 0.008*\"years\"'),\n",
       " (2,\n",
       "  '0.007*\"cent\" + 0.006*\"animals\" + 0.005*\"milk\" + 0.005*\"table\" + 0.005*\"disease\" + 0.004*\"animal\" + 0.004*\"blood\" + 0.004*\"indian\" + 0.004*\"cattle\" + 0.004*\"results\"'),\n",
       " (3,\n",
       "  '0.029*\"ganja\" + 0.019*\"bhang\" + 0.015*\"use\" + 0.013*\"drugs\" + 0.012*\"charas\" + 0.010*\"hemp\" + 0.007*\"drug\" + 0.007*\"district\" + 0.006*\"people\" + 0.006*\"plant\"'),\n",
       " (4,\n",
       "  '0.028*\"year\" + 0.022*\"veterinary\" + 0.018*\"total\" + 0.018*\"number\" + 0.010*\"rs\" + 0.009*\"district\" + 0.009*\"department\" + 0.009*\"animals\" + 0.009*\"government\" + 0.008*\"table\"')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the LDA model\n",
    "lda = models.LdaModel(corpus=corpusNA, num_topics=5, id2word=id2wordNA, passes=80)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics - just with 'lunatic asylums' corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mental asylum in Tezpur and Burma\n",
    "- Use of ganja, bhang, charas by people in the district: ganja mania\n",
    "- report of total deaths and cases of disease of patients\n",
    "- males and females in lunatic asylums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics -  with 'lunatic asylums'and 'mental health' corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use of ganja, bhang, charas by people in the district: ganja mania\n",
    "- total vaccinations per year of males and females in asylums \n",
    "\n",
    "Unrelated\n",
    "- number of plague cases and deaths in hospitals\n",
    "- diseases in animals (e.g. cattle)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
